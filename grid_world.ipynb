{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сеточный мир"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условия: задана матрица состояний 5х5, функция ценности перехода из одного состояния в другое, $\\gamma = 0.9$. Стратегия выбора перехода (действия) - равновероятная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: для каждого состояния вычислить его ценность. Вычисления провести двумя методами: путём решения СЛАУ и методом Монте-Карло."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mesh_world_problem.png\" width=600 height=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Монте-Карло"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию, которая делает броски по Монте-Карло и для перехода из одного состояния в другое пользуется предоставленной стратегией.\n",
    "\n",
    "Стратегия - это функция, которая принимает на вход текущее состояние и возвращает следующее состояние и награду за переход в следующее состояние."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mc_solution(\n",
    "        strategy: Callable[[int, int], Tuple[int, int, float]],\n",
    "        width: int=5, \n",
    "        height: int=5, \n",
    "        gamma: float=0.9, \n",
    "        exp_cnt: int=10**6\n",
    "    ):\n",
    "    '''\n",
    "    Monte-Carlo based solution. Model `exp_cnt` experiments, extract average out of results.\n",
    "    Arguments:\n",
    "    * width, height - size of statuses' matrix.\n",
    "    * gamma - decay coefficient.\n",
    "    * exp_cnt - number of experiments per state.\n",
    "    * strategy - callable object, which accepts current state (starting from (1,1)) and returns next state (also starting from (1,1))\n",
    "and reward for passing to this state.\n",
    "    \n",
    "    Returns numpy.ndarray of size height*width, which elements are value function of corresponding state.\n",
    "    '''\n",
    "    def _make_throw(i, j, gamma, gamma_i = -1):\n",
    "        eps = 10**(-20)\n",
    "        result_i = 0.\n",
    "        gamma_i = gamma if gamma_i == -1 else gamma_i\n",
    "        \n",
    "        next_i, next_j, reward = strategy(i, j)\n",
    "        result_i += reward\n",
    "        if gamma_i >= eps:\n",
    "            result_i += gamma_i * _make_throw(next_i, next_j, gamma, gamma_i*gamma)\n",
    "        \n",
    "        return result_i\n",
    "    \n",
    "    result = np.zeros((height, width))\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            total_value = 0.\n",
    "            \n",
    "            for _ in range(exp_cnt):\n",
    "                total_value += _make_throw(i+1, j+1, gamma)\n",
    "            result[i,j] = total_value / exp_cnt\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим стратегию, которая соответствует нашей задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def strategy(i: int, j: int):\n",
    "    possible_states = [\n",
    "        (i+1, j),\n",
    "        (i-1, j),\n",
    "        (i, j+1),\n",
    "        (i, j-1)\n",
    "    ]\n",
    "    reward = 0.\n",
    "    \n",
    "    next_state = possible_states[np.random.randint(0, len(possible_states))]\n",
    "    \n",
    "    # Check for special states.\n",
    "    if i == 1 and j == 2:\n",
    "        next_state = (5,2)\n",
    "        reward = 10.\n",
    "    elif i == 1 and j == 4:\n",
    "        next_state = (3,4)\n",
    "        reward = 5.\n",
    "        \n",
    "    # Check if we are out of grid.\n",
    "    if next_state[0] < 1 or next_state[0] > 5 or \\\n",
    "       next_state[1] < 1 or next_state[1] > 5:\n",
    "        next_state = (i,j)\n",
    "        reward = -1.\n",
    "    \n",
    "    return *next_state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.59008863  9.29338037  4.3727448   5.15254297  0.92513858]\n",
      " [ 0.5995925   2.69892745  1.21601399  1.21520269  0.08390912]\n",
      " [-0.28401662  0.8429217   0.55434667  0.12485087 -0.53017915]\n",
      " [-0.76850065 -0.3020796  -0.31179786 -0.30295974 -1.00429402]\n",
      " [-1.35037959 -0.87185098 -0.90029531 -1.02843573 -1.36728573]]\n"
     ]
    }
   ],
   "source": [
    "print(mc_solution(strategy, exp_cnt=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.92336535  9.33980491  4.04449744  5.07761607  0.87255929]\n",
      " [ 0.95962867  2.59067479  1.5676385   1.30325653  0.04143557]\n",
      " [-0.32747972  0.44869587  0.31706527  0.17354382 -0.53247775]\n",
      " [-0.7740485  -0.28153534 -0.20158665 -0.335326   -0.82808145]\n",
      " [-1.32019219 -0.91071728 -0.82738497 -0.8842017  -1.38595556]]\n"
     ]
    }
   ],
   "source": [
    "print(mc_solution(strategy, exp_cnt=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.7965825   9.3296535   4.09893173  5.09685239  0.93112314]\n",
      " [ 0.77731217  2.63244149  1.67177777  1.41307513  0.03839509]\n",
      " [-0.29137979  0.44934179  0.34575188  0.14816086 -0.51668063]\n",
      " [-0.80676709 -0.29933235 -0.20522902 -0.35632894 -0.8485803 ]\n",
      " [-1.37335368 -0.87542537 -0.76551391 -0.90011059 -1.37683771]]\n"
     ]
    }
   ],
   "source": [
    "print(mc_solution(strategy, exp_cnt=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение СЛАУ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы знаем следующее: $\\nu_{\\pi}(s) = \\sum_{a}{\\pi(a|s)}\\sum_{s'}\\sum_{r}p(s',r|s,a)[r + \\gamma\\nu_{\\pi}(s')]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша стратегия - равновероятная, поэтому $\\pi(a|s) = 1/4$ для обычных клеток (всего четыре различных действия), $\\pi(a|s) = 1$ для клеток A и B (в них мы можем сделать только одно конкретное действие).\n",
    "\n",
    "Также нам известно, что при любом действии у нас возможно только одно вознаграждение и переход в одно конкретное состояние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, изначальная формула преобразуется в \n",
    "\n",
    "$\\nu_{\\pi}(s) = \\begin{cases} \\sum_{a}\\frac{1}{4}(r_{a} + \\gamma\\nu_{\\pi}(s'_{a})), & s \\notin \\{A,B\\} \\\\ r + \\gamma\\nu_{\\pi}(s'), & s \\in \\{A,B\\} \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подставив в формулу каждое состояние $s$, получим СЛАУ, решив которую, мы получим искомые стоимости.\n",
    "\n",
    "Формула выше в матричном виде будет иметь вид $Ax + b = x$, \n",
    "\n",
    "где $b = (\\sum_{a_{s_{1}}}\\frac{1}{4}r_{a_{s_{1}}} \\dots \\sum_{a_{s_{n}}}\\frac{1}{4}r_{a_{s_{n}}})^{T}$ - вектор свободных членов, которые являются матожиданием награды в соответствующих состояниях,\n",
    "\n",
    "$a_{ij} = \\begin{cases} \\sum{\\frac{\\gamma}{4}}, & \\mbox{если из состояния } s_{i} \\mbox{ можно перейти в состояние } s_{j} \\mbox{ и } s_{i} \\notin \\{A,B\\} \\mbox{. Сумма считается по всем действиям, в результате которых из состояния } s_{i} \\mbox{ достигается состояние } s_{j}, \\\\ \\gamma, & \\mbox{если из состояния } s_{i} \\mbox{ можно перейти в состояние } s_{j} \\mbox{ и } s_{i} \\in \\{A,B\\}, \\\\ 0, & \\mbox{иначе.} \\end{cases}$,\n",
    "\n",
    "$x$ - вектор $\\nu_{\\pi}(s)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовав это уравнение, получим $(A-E)x = -b$, \n",
    "\n",
    "оно же $(E - A)x = b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Generator, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def system_solution(\n",
    "        action_generator: Callable[[int, int], Generator[Tuple[int, int, float], None, None]],\n",
    "        n: int=5,\n",
    "        m: int=5,\n",
    "        gamma: float=0.9\n",
    "    ):\n",
    "    n,m = 5,5\n",
    "    a = np.eye(n*m)\n",
    "    b = np.zeros(n*m)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            current_state = i*m + j\n",
    "            states_to_update = set()\n",
    "            \n",
    "            for state_info in action_generator(i+1, j+1):\n",
    "                next_state = (state_info[0]-1)*m + (state_info[1]-1)\n",
    "                reward = state_info[2]\n",
    "                \n",
    "                states_to_update.add(next_state)\n",
    "                b[current_state] += reward\n",
    "                \n",
    "            states_cnt = len(states_to_update)\n",
    "            for state in states_to_update:\n",
    "                a[current_state, state] -= gamma / states_cnt\n",
    "    \n",
    "    result = np.linalg.solve(a, b)\n",
    "    result.resize((n,m))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_generator(i: int, j: int):\n",
    "    possible_states = [\n",
    "        (i+1, j),\n",
    "        (i-1, j),\n",
    "        (i, j+1),\n",
    "        (i, j-1)\n",
    "    ]\n",
    "    \n",
    "    if i == 1 and j == 2:\n",
    "        yield 5, 2, 10.\n",
    "    elif i == 1 and j == 4:\n",
    "        yield 3, 4, 5.\n",
    "    else:\n",
    "        for state in possible_states:\n",
    "            reward = 0.\n",
    "            \n",
    "            if state[0] < 1 or state[0] > 5 or \\\n",
    "               state[1] < 1 or state[1] > 5:\n",
    "                state = (i,j)\n",
    "                reward = -1. / 4\n",
    "                \n",
    "            yield *state, reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.86436159  8.9207585   4.51751998  5.40817026  1.91987469]\n",
      " [ 1.76275187  3.12105378  2.34252893  2.01204579  0.73820401]\n",
      " [ 0.19739664  0.84531084  0.76062014  0.45352252 -0.27810667]\n",
      " [-0.81702983 -0.32213352 -0.26082831 -0.47890363 -1.03853838]\n",
      " [-1.57836588 -1.19915722 -1.11881992 -1.28261642 -1.70906634]]\n"
     ]
    }
   ],
   "source": [
    "print(system_solution(action_generator))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
